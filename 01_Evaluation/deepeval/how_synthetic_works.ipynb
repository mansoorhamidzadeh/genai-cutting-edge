{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# *import packages and module*",
   "id": "1f9b9d413bf2d693"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional, List\n",
    "import random\n",
    "import numpy as np\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from custom_models import CustomLLModel, CustomEmbeddingModel\n",
    "from synthetic_dataset_generate import DeepEvalSynthesizer\n",
    "from utils.llm_con import get_chat_openai\n",
    "\n",
    "llm = get_chat_openai()\n",
    "deep_e = DeepEvalSynthesizer(CustomLLModel(llm), CustomEmbeddingModel())\n",
    "embeddings = CustomEmbeddingModel()"
   ],
   "id": "e3249885267a97c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# *chunking*",
   "id": "531637fe751a0c28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "path = '../../Datasets/docx_example.docx'\n",
    "text_splitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "loader = TextLoader(\"../../Datasets/txt_example.txt\")\n",
    "raw_chunks = loader.load_and_split(text_splitter)"
   ],
   "id": "3df6b3f361535a5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "raw_chunks\n",
   "id": "d96d93658fecb4b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# *embedding and Context Generation*",
   "id": "d3d80643ac45ef51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "content = [rc.page_content for rc in raw_chunks]\n",
    "embeddings = embeddings.embed_texts(content)"
   ],
   "id": "645932381475034c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "reference_index = random.randint(0, len(embeddings) - 1)\n",
    "reference_embedding = embeddings[reference_index]\n",
    "contexts = [content[reference_index]]\n",
    "\n",
    "similarity_threshold = 0.7\n",
    "similar_indices = []\n",
    "for i, embedding in enumerate(embeddings):\n",
    "    product = np.dot(reference_embedding, embedding)\n",
    "    norm = np.linalg.norm(reference_embedding) * np.linalg.norm(embedding)\n",
    "    similarity = product / norm\n",
    "    if similarity >= similarity_threshold:\n",
    "        similar_indices.append(i)\n",
    "\n",
    "for i in similar_indices:\n",
    "    contexts.append(content[i])"
   ],
   "id": "742cc314131984d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# *Query Generation*",
   "id": "910076f4962fda09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = f\"\"\"I want you act as a copywriter. Based on the given context,\n",
    "which is list of strings, please generate a list of JSON objects\n",
    "with a `input` key. The `input` can either be a question or a\n",
    "statement that can be addressed by the given context.\n",
    "\n",
    "contexts:\n",
    "{contexts}\"\"\"\n",
    "\n",
    "query = llm.invoke(prompt)"
   ],
   "id": "4429b6f300f5bf7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(query.content)",
   "id": "fcb06a6f784145fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# *Query Evolution*",
   "id": "bc1c334ab9c6b7c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "example_generated_query = \"what is recipe of Apple Turnovers\"\n",
    "context = contexts\n",
    "original_input = example_generated_query\n",
    "num_evolution_steps = 3\n",
    "\n",
    "multi_context_template = f\"\"\"\n",
    "I want you to rewrite the given `input` so that it requires readers to use information from all elements in `Context`.\n",
    "\n",
    "1. `Input` should require information from all `Context` elements.\n",
    "2. `Rewritten Input` must be concise and fully answerable from `Context`.\n",
    "3. Do not use phrases like 'based on the provided context.'\n",
    "4. `Rewritten Input` should not exceed 15 words.\n",
    "\n",
    "Context: {context}\n",
    "Input: {original_input}\n",
    "Rewritten Input:\n",
    "\"\"\"\n",
    "\n",
    "reasoning_template = f\"\"\"\n",
    "I want you to rewrite the given `input` so that it explicitly requests multi-step reasoning.\n",
    "\n",
    "1. `Rewritten Input` should require multiple logical connections or inferences.\n",
    "2. `Rewritten Input` should be concise and understandable.\n",
    "3. Do not use phrases like 'based on the provided context.'\n",
    "4. `Rewritten Input` must be fully answerable from `Context`.\n",
    "5. `Rewritten Input` should not exceed 15 words.\n",
    "\n",
    "Context: {context}\n",
    "Input: {original_input}\n",
    "Rewritten Input:\n",
    "\"\"\"\n",
    "\n",
    "hypothetical_scenario_template = f\"\"\"\n",
    "I want you to rewrite the given `input` to incorporate a hypothetical or speculative scenario.\n",
    "\n",
    "1. `Rewritten Input` should encourage applying knowledge from `Context` to deduce outcomes.\n",
    "2. `Rewritten Input` should be concise and understandable.\n",
    "3. Do not use phrases like 'based on the provided context.'\n",
    "4. `Rewritten Input` must be fully answerable from `Context`.\n",
    "5. `Rewritten Input` should not exceed 15 words.\n",
    "\n",
    "Context: {context}\n",
    "Input: {original_input}\n",
    "Rewritten Input:\n",
    "\"\"\"\n",
    "evolution_templates = [multi_context_template, reasoning_template, hypothetical_scenario_template]\n",
    "\n",
    "\n",
    "def evolve_query(original_input: str, context, steps: int) -> str:\n",
    "    current_input = original_input\n",
    "    for _ in range(steps):\n",
    "        chosen_template = random.choice(evolution_templates)\n",
    "        evolved_prompt = (\n",
    "            chosen_template\n",
    "            .replace(\"{context}\", str(context))\n",
    "            .replace(\"{original_input}\", current_input)\n",
    "        )\n",
    "        print(\"Prompt sent to LLM:\\n\", evolved_prompt)\n",
    "\n",
    "        response = llm.invoke(evolved_prompt)\n",
    "        current_input = response.content\n",
    "\n",
    "    return current_input\n",
    "\n",
    "\n",
    "evolved_query = evolve_query(original_input, context, num_evolution_steps)"
   ],
   "id": "7ea9737d2b8a39a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "evolved_query",
   "id": "ee098ae0197ce73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# *Expected Output Generation*",
   "id": "d20cb41581678bf2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "expected_output_template = f\"\"\"\n",
    "I want you to generate an answer for the given `input`. This answer has to be factually aligned to the provided context.\n",
    "\n",
    "Context: {context}\n",
    "Input: {evolved_query}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = expected_output_template.replace(\"{context}\", str(context)).replace(\"{evolved_query}\", evolved_query)\n",
    "\n",
    "expected_output = llm.invoke(prompt)"
   ],
   "id": "899206620b86e8dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(expected_output.content)",
   "id": "55932a18bbb77407",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "class SyntheticData(BaseModel):\n",
    "    query: str\n",
    "    expected_output: Optional[str]\n",
    "    context: List[str]\n",
    "\n",
    "\n",
    "def as_str(x):\n",
    "    return x.content if hasattr(x, \"content\") else x\n",
    "\n",
    "\n",
    "synthetic_data = SyntheticData(\n",
    "    query=evolved_query,\n",
    "    expected_output=as_str(expected_output),\n",
    "    context=context,\n",
    ")\n",
    "\n",
    "synthetic_dataset = []\n",
    "synthetic_dataset.append(synthetic_data)"
   ],
   "id": "96623e70cb4dca8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "synthetic_dataset[0].context",
   "id": "1c11bd9661556489",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# *Generating Synthetic Datasets Using DeepEval*",
   "id": "108a46683c921aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "path = '../../Datasets/txt_example.txt'\n",
    "\n",
    "result = deep_e.generate_goldens_from_documents(document_paths=path)"
   ],
   "id": "bf93a721a10ac9b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "deep_e.to_dataframe()",
   "id": "45ff3ee6f0c5cbdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "205a2f3c2b7d4087"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
