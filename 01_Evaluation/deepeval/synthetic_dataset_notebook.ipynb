{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Synthetic Dataset Generation for RAG Systems\n",
    "\n",
    "This notebook demonstrates how to create synthetic datasets for Retrieval-Augmented Generation (RAG) systems.\n",
    "The process involves:\n",
    "1. Document loading and chunking\n",
    "2. Embedding generation and similarity-based context selection\n",
    "3. Query generation from contexts\n",
    "4. Query evolution through multiple transformation steps\n",
    "5. Expected output generation\n",
    "6. Final synthetic dataset creation using DeepEval\n",
    "\n",
    "\n"
   ],
   "id": "60855a400aeef09b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Import Packages and Initialize Models\n",
    "\n",
    "Setting up all required dependencies and initializing the core models:\n",
    "- CustomLLModel: Wrapper for language model operations\n",
    "- CustomEmbeddingModel: Handles text embeddings\n",
    "- DeepEvalSynthesizer: Advanced synthetic data generation\n",
    "\n"
   ],
   "id": "3e9d222238407bb2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T06:42:29.015340Z",
     "start_time": "2025-08-03T06:42:22.955172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional, List\n",
    "import random\n",
    "import numpy as np\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from custom_models import CustomLLModel, CustomEmbeddingModel\n",
    "from synthetic_dataset_generate import DeepEvalSynthesizer\n",
    "from utils.llm_con import get_chat_openai\n",
    "\n",
    "# Configure logging for better tracking (Windows-compatible)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('synthetic_dataset_generation.log', encoding='utf-8')\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set console handler encoding to handle Unicode properly\n",
    "for handler in logging.getLogger().handlers:\n",
    "    if isinstance(handler, logging.StreamHandler):\n",
    "        handler.setStream(sys.stdout)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SYNTHETIC DATASET GENERATION PIPELINE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print()\n",
    "\n",
    "# Initialize models\n",
    "logger.info(\"Initializing language models and embedding models...\")\n",
    "try:\n",
    "    llm = get_chat_openai()\n",
    "    deep_e = DeepEvalSynthesizer(CustomLLModel(llm), CustomEmbeddingModel())\n",
    "    embeddings = CustomEmbeddingModel()\n",
    "    logger.info(\"Models initialized successfully\")\n",
    "    print(\"‚úÖ All models loaded and ready\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to initialize models: {str(e)}\")\n",
    "    raise\n"
   ],
   "id": "26c5a6529084a21a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SYNTHETIC DATASET GENERATION PIPELINE\n",
      "============================================================\n",
      "Started at: 2025-08-03 10:12:28\n",
      "\n",
      "2025-08-03 10:12:28,694 - INFO - Initializing language models and embedding models...\n",
      "2025-08-03 10:12:29,012 - INFO - Models initialized successfully\n",
      "‚úÖ All models loaded and ready\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Document Loading and Text Chunking\n",
    "\n",
    "Loading documents and splitting them into manageable chunks:\n",
    "- TokenTextSplitter ensures consistent chunk sizes based on token count\n",
    "- chunk_size=1000: Each chunk contains roughly 1000 tokens\n",
    "- chunk_overlap=0: No overlap between chunks to avoid redundancy\n",
    "\n",
    "Note: Currently set up for both .docx and .txt files, but only .txt is being used\n",
    "\"\"\"\n"
   ],
   "id": "5917bd3ab01748a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T06:42:38.717082Z",
     "start_time": "2025-08-03T06:42:38.279960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logger.info(\"Starting document loading and chunking process...\")\n",
    "\n",
    "# Document paths\n",
    "docx_path = '../../Datasets/docx_example.docx'  # Available but not used in current flow\n",
    "txt_path = \"../../Datasets/txt_example.txt\"\n",
    "\n",
    "# Configure text splitter\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 0\n",
    "text_splitter = TokenTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\n",
    "logger.info(f\"Text splitter configured - chunk_size: {chunk_size}, overlap: {chunk_overlap}\")\n",
    "\n",
    "# Load and split document\n",
    "try:\n",
    "    loader = TextLoader(txt_path)\n",
    "    raw_chunks = loader.load_and_split(text_splitter)\n",
    "    \n",
    "    logger.info(f\"Document loaded successfully from: {txt_path}\")\n",
    "    logger.info(f\"Generated {len(raw_chunks)} chunks\")\n",
    "    \n",
    "    print(f\"Document Processing Summary:\")\n",
    "    print(f\"- Source file: {txt_path}\")\n",
    "    print(f\"- Total chunks created: {len(raw_chunks)}\")\n",
    "    print(f\"- Chunk size: {chunk_size} tokens\")\n",
    "    print(f\"- Chunk overlap: {chunk_overlap} tokens\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load document: {str(e)}\")\n",
    "    raise\n"
   ],
   "id": "a232b3b6ee2e25a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:12:38,283 - INFO - Starting document loading and chunking process...\n",
      "2025-08-03 10:12:38,711 - INFO - Text splitter configured - chunk_size: 1000, overlap: 0\n",
      "2025-08-03 10:12:38,714 - INFO - Document loaded successfully from: ../../Datasets/txt_example.txt\n",
      "2025-08-03 10:12:38,714 - INFO - Generated 1 chunks\n",
      "Document Processing Summary:\n",
      "- Source file: ../../Datasets/txt_example.txt\n",
      "- Total chunks created: 1\n",
      "- Chunk size: 1000 tokens\n",
      "- Chunk overlap: 0 tokens\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T06:42:43.234202Z",
     "start_time": "2025-08-03T06:42:43.225880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display chunk information for verification\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CHUNK PREVIEW\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for i, chunk in enumerate(raw_chunks[:3]):  # Show first 3 chunks\n",
    "    print(f\"\\nChunk {i+1}:\")\n",
    "    print(f\"Content length: {len(chunk.page_content)} characters\")\n",
    "    print(f\"Preview: {chunk.page_content[:200]}...\")\n",
    "    if i < len(raw_chunks) - 1:\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "if len(raw_chunks) > 3:\n",
    "    print(f\"\\n... and {len(raw_chunks) - 3} more chunks\")\n",
    "\n",
    "raw_chunks\n"
   ],
   "id": "2fff86af0c3a8a3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "CHUNK PREVIEW\n",
      "==================================================\n",
      "\n",
      "Chunk 1:\n",
      "Content length: 1292 characters\n",
      "Preview: Apple Turnovers\n",
      "\n",
      "2 prepared 15 oz. pie crusts\n",
      "3 cups thinly sliced apples with peel\n",
      "1/2 cup brown sugar\n",
      "1 tsp. cinnamon\n",
      "2 tsp. fresh lemon juice\n",
      "2 Tbsp. flour\n",
      "2 Tbsp. sugar\n",
      "1/2 tsp. salt\n",
      "1 tsp. vanill...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../../Datasets/txt_example.txt'}, page_content='Apple Turnovers\\n\\n2 prepared 15 oz. pie crusts\\n3 cups thinly sliced apples with peel\\n1/2 cup brown sugar\\n1 tsp. cinnamon\\n2 tsp. fresh lemon juice\\n2 Tbsp. flour\\n2 Tbsp. sugar\\n1/2 tsp. salt\\n1 tsp. vanilla\\n2 Tbsp. Butter\\n\\nLet pie crust stand at room temperature while preparing the other\\ningredients. Combine apples, brown sugar, cinnamon and lemon \\njuice in pan. Add 2 Tbsp. water to allow easy mixing.  Cook\\nover medium heat until mixture bubbles.  Cover and continue cooking\\nover low heat for 10 minutes stirring occasionally.\\nGradually add flour, sugar and salt to mixture and cook until the \\nmixture begins to thicken.  Add in vanilla and butter and remove \\nmixture from heat.  Spread out pie crusts on ungreased cookie sheet.\\nSpread apple mixture evenly on half of each crust.  Fold over\\nother side of crust and press edges with a little warm water to\\nseal.  Cut small slits in top of crust and bake at 375 degrees\\nfor 30 minutes until crust is golden brown.  Serve warm.  These\\nturnovers will be a real hit.  If you would like, cut the pie crusts\\ninto smaller pieces and make individual turnovers.  You can serve\\nthese with ice cream or frozen yogurt.\\n\\nThe Skinny:  This recipe does have some sugar in it but it is not\\nreally that bad.  Leave off the ice cream and you will be doing\\nfine. ')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Embedding Generation and Context Selection\n",
    "\n",
    "Creating embeddings for all chunks and selecting relevant contexts:\n",
    "\n",
    "Process:\n",
    "1. Extract text content from all chunks\n",
    "2. Generate embeddings for each chunk\n",
    "3. Randomly select a reference chunk\n",
    "4. Find similar chunks using cosine similarity\n",
    "5. Combine reference and similar chunks as context\n",
    "\n",
    "Similarity threshold: 0.7 (configurable)\n",
    "\"\"\n"
   ],
   "id": "8c78c90a9f30b4b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T06:43:18.278348Z",
     "start_time": "2025-08-03T06:43:01.865733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logger.info(\"Starting embedding generation and context selection...\")\n",
    "\n",
    "# Extract content from chunks\n",
    "content = [rc.page_content for rc in raw_chunks]\n",
    "logger.info(f\"Extracted content from {len(content)} chunks\")\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"üîÑ Generating embeddings for all chunks...\")\n",
    "try:\n",
    "    embeddings_vectors = embeddings.embed_texts(content)\n",
    "    logger.info(f\"Generated embeddings for {len(embeddings_vectors)} text chunks\")\n",
    "    print(f\"‚úÖ Embeddings generated successfully\")\n",
    "    print(f\"- Embedding dimensions: {len(embeddings_vectors[0]) if embeddings_vectors else 'N/A'}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to generate embeddings: {str(e)}\")\n",
    "    raise\n"
   ],
   "id": "2dfc1504738e1d71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:13:01,869 - INFO - Starting embedding generation and context selection...\n",
      "2025-08-03 10:13:01,870 - INFO - Extracted content from 1 chunks\n",
      "üîÑ Generating embeddings for all chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manso\\DataspellProjects\\genai-cutting-edge\\01_Evaluation\\deepeval\\custom_models.py:42: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.model = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:13:10,192 - INFO - PyTorch version 2.6.0+cu118 available.\n",
      "2025-08-03 10:13:10,671 - INFO - Load pretrained SentenceTransformer: PartAI/Tooka-SBERT-V2-Large\n",
      "2025-08-03 10:13:18,275 - INFO - Generated embeddings for 1 text chunks\n",
      "‚úÖ Embeddings generated successfully\n",
      "- Embedding dimensions: 1024\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T06:43:24.292631Z",
     "start_time": "2025-08-03T06:43:24.279919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Context selection using similarity\n",
    "print(\"\\nüîÑ Selecting relevant contexts using similarity matching...\")\n",
    "\n",
    "# Randomly select reference chunk\n",
    "reference_index = random.randint(0, len(embeddings_vectors) - 1)\n",
    "reference_embedding = embeddings_vectors[reference_index]\n",
    "contexts = [content[reference_index]]\n",
    "\n",
    "logger.info(f\"Reference chunk selected: index {reference_index}\")\n",
    "print(f\"üìå Reference chunk index: {reference_index}\")\n",
    "\n",
    "# Find similar chunks\n",
    "similarity_threshold = 0.7\n",
    "similar_indices = []\n",
    "\n",
    "print(f\"üîç Finding chunks with similarity >= {similarity_threshold}...\")\n",
    "\n",
    "for i, embedding in enumerate(embeddings_vectors):\n",
    "    # Calculate cosine similarity\n",
    "    product = np.dot(reference_embedding, embedding)\n",
    "    norm = np.linalg.norm(reference_embedding) * np.linalg.norm(embedding)\n",
    "    \n",
    "    if norm == 0:\n",
    "        similarity = 0\n",
    "    else:\n",
    "        similarity = product / norm\n",
    "    \n",
    "    if similarity >= similarity_threshold:\n",
    "        similar_indices.append((i, similarity))\n",
    "        logger.debug(f\"Similar chunk found: index {i}, similarity: {similarity:.3f}\")\n",
    "\n",
    "# Sort by similarity (highest first)\n",
    "similar_indices.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Add similar chunks to contexts\n",
    "for i, similarity in similar_indices:\n",
    "    if i != reference_index:  # Avoid duplicating reference chunk\n",
    "        contexts.append(content[i])\n",
    "\n",
    "logger.info(f\"Context selection completed:\")\n",
    "logger.info(f\"- Reference chunk: 1\")\n",
    "logger.info(f\"- Similar chunks found: {len(similar_indices)}\")\n",
    "logger.info(f\"- Total contexts: {len(contexts)}\")\n",
    "\n",
    "print(f\"\\nüìä Context Selection Results:\")\n",
    "print(f\"- Reference chunk: index {reference_index}\")\n",
    "print(f\"- Similar chunks found: {len(similar_indices)}\")\n",
    "print(f\"- Total context pieces: {len(contexts)}\")\n",
    "\n",
    "if similar_indices:\n",
    "    print(f\"- Similarity scores: {[f'{sim:.3f}' for _, sim in similar_indices[:5]]}\")\n"
   ],
   "id": "a63774b0a1233d12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Selecting relevant contexts using similarity matching...\n",
      "2025-08-03 10:13:24,285 - INFO - Reference chunk selected: index 0\n",
      "üìå Reference chunk index: 0\n",
      "üîç Finding chunks with similarity >= 0.7...\n",
      "2025-08-03 10:13:24,287 - INFO - Context selection completed:\n",
      "2025-08-03 10:13:24,288 - INFO - - Reference chunk: 1\n",
      "2025-08-03 10:13:24,289 - INFO - - Similar chunks found: 1\n",
      "2025-08-03 10:13:24,290 - INFO - - Total contexts: 1\n",
      "\n",
      "üìä Context Selection Results:\n",
      "- Reference chunk: index 0\n",
      "- Similar chunks found: 1\n",
      "- Total context pieces: 1\n",
      "- Similarity scores: ['1.000']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Initial Query Generation\n",
    "\n",
    "Generate initial queries based on the selected contexts using the LLM.\n",
    "The prompt asks the model to create questions or statements that can be\n",
    "addressed by the given context.\n",
    "\n",
    "This step creates the foundation queries that will be evolved in the next step.\n",
    "\n"
   ],
   "id": "1b179115ccec1779"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T06:43:47.790504Z",
     "start_time": "2025-08-03T06:43:41.929431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logger.info(\"Starting initial query generation...\")\n",
    "\n",
    "print(\"\\nüîÑ Generating initial queries from contexts...\")\n",
    "\n",
    "# Original prompt - DO NOT MODIFY\n",
    "prompt = f\"\"\"I want you act as a copywriter. Based on the given context,\n",
    "which is list of strings, please generate a list of JSON objects\n",
    "with a `input` key. The `input` can either be a question or a\n",
    "statement that can be addressed by the given context.\n",
    "\n",
    "contexts:\n",
    "{contexts}\"\"\"\n",
    "\n",
    "try:\n",
    "    query_response = llm.invoke(prompt)\n",
    "    logger.info(\"Initial query generated successfully\")\n",
    "    print(\"‚úÖ Initial queries generated\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to generate initial query: {str(e)}\")\n",
    "    raise\n"
   ],
   "id": "bbf3ab1c9d7ef2e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:13:41,932 - INFO - Starting initial query generation...\n",
      "\n",
      "üîÑ Generating initial queries from contexts...\n",
      "2025-08-03 10:13:47,766 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:13:47,785 - INFO - Initial query generated successfully\n",
      "‚úÖ Initial queries generated\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T06:43:47.805431Z",
     "start_time": "2025-08-03T06:43:47.800928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GENERATED QUERIES\")\n",
    "print(\"=\"*50)\n",
    "print(query_response.content)\n",
    "print(\"=\"*50)\n"
   ],
   "id": "43ff4495bcf1418",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "GENERATED QUERIES\n",
      "==================================================\n",
      "[\n",
      "  {\n",
      "    \"input\": \"What ingredients are needed to make Apple Turnovers?\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"How long should the apple mixture be cooked before adding the flour and sugar?\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"What temperature should the oven be preheated to when baking Apple Turnovers?\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"How long should Apple Turnovers be baked in the oven?\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"What should be done to seal the edges of the Apple Turnovers?\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"Can you make individual-sized Apple Turnovers using this recipe?\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"What can you serve Apple Turnovers with?\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"Why might someone consider this recipe 'skinny'?\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"What is the purpose of adding lemon juice to the apple mixture?\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"How do you prepare the pie crusts before adding the filling?\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"What is the role of butter in the final apple mixture?\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"Can you bake Apple Turnovers without cutting slits on top?\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"What happens if you skip the flour when thickening the apple mixture?\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"How do you know when the Apple Turnovers are done baking?\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"Is it necessary to use unsalted butter in this recipe?\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"Can you use pre-sliced apples instead of thinly sliced ones?\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"What is the benefit of letting the pie crusts come to room temperature before using?\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"Can you make Apple Turnovers ahead of time and reheat them?\"\n",
      "  }\n",
      "]\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Query Evolution Process\n",
    "\n",
    "Evolve the initial query through multiple transformation steps to create\n",
    "more sophisticated and challenging questions.\n",
    "\n",
    "Evolution Templates:\n",
    "1. Multi-context: Requires information from all context elements\n",
    "2. Reasoning: Requests multi-step logical reasoning\n",
    "3. Hypothetical scenario: Incorporates speculative scenarios\n",
    "\n",
    "Process:\n",
    "- Start with example query\n",
    "- Apply random evolution templates for specified steps\n",
    "- Each step transforms the query to be more complex\n",
    "\n",
    "Configuration:\n",
    "- Example query: \"what is recipe of Apple Turnovers\"\n",
    "- Evolution steps: 3\n",
    "- Templates: Multi-context, Reasoning, Hypothetical scenario\n",
    "\n"
   ],
   "id": "b7f410ec89f1e6e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T06:44:05.248808Z",
     "start_time": "2025-08-03T06:44:02.294356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logger.info(\"Starting query evolution process...\")\n",
    "\n",
    "# Evolution configuration\n",
    "example_generated_query = \"what is recipe of Apple Turnovers\"\n",
    "context = contexts\n",
    "original_input = example_generated_query\n",
    "num_evolution_steps = 3\n",
    "\n",
    "logger.info(f\"Evolution configuration:\")\n",
    "logger.info(f\"- Original query: '{original_input}'\")\n",
    "logger.info(f\"- Evolution steps: {num_evolution_steps}\")\n",
    "logger.info(f\"- Context pieces: {len(context)}\")\n",
    "\n",
    "print(f\"\\nüîÑ Query Evolution Process\")\n",
    "print(f\"- Original query: '{original_input}'\")\n",
    "print(f\"- Evolution steps: {num_evolution_steps}\")\n",
    "print(f\"- Available templates: Multi-context, Reasoning, Hypothetical scenario\")\n",
    "\n",
    "# Evolution templates - DO NOT MODIFY THESE PROMPTS\n",
    "multi_context_template = f\"\"\"\n",
    "I want you to rewrite the given `input` so that it requires readers to use information from all elements in `Context`.\n",
    "\n",
    "1. `Input` should require information from all `Context` elements.\n",
    "2. `Rewritten Input` must be concise and fully answerable from `Context`.\n",
    "3. Do not use phrases like 'based on the provided context.'\n",
    "4. `Rewritten Input` should not exceed 15 words.\n",
    "\n",
    "Context: {context}\n",
    "Input: {original_input}\n",
    "Rewritten Input:\n",
    "\"\"\"\n",
    "\n",
    "reasoning_template = f\"\"\"\n",
    "I want you to rewrite the given `input` so that it explicitly requests multi-step reasoning.\n",
    "\n",
    "1. `Rewritten Input` should require multiple logical connections or inferences.\n",
    "2. `Rewritten Input` should be concise and understandable.\n",
    "3. Do not use phrases like 'based on the provided context.'\n",
    "4. `Rewritten Input` must be fully answerable from `Context`.\n",
    "5. `Rewritten Input` should not exceed 15 words.\n",
    "\n",
    "Context: {context}\n",
    "Input: {original_input}\n",
    "Rewritten Input:\n",
    "\"\"\"\n",
    "\n",
    "hypothetical_scenario_template = f\"\"\"\n",
    "I want you to rewrite the given `input` to incorporate a hypothetical or speculative scenario.\n",
    "\n",
    "1. `Rewritten Input` should encourage applying knowledge from `Context` to deduce outcomes.\n",
    "2. `Rewritten Input` should be concise and understandable.\n",
    "3. Do not use phrases like 'based on the provided context.'\n",
    "4. `Rewritten Input` must be fully answerable from `Context`.\n",
    "5. `Rewritten Input` should not exceed 15 words.\n",
    "\n",
    "Context: {context}\n",
    "Input: {original_input}\n",
    "Rewritten Input:\n",
    "\"\"\"\n",
    "\n",
    "evolution_templates = [multi_context_template, reasoning_template, hypothetical_scenario_template]\n",
    "template_names = [\"Multi-context\", \"Reasoning\", \"Hypothetical scenario\"]\n",
    "\n",
    "logger.info(f\"Loaded {len(evolution_templates)} evolution templates\")\n",
    "\n",
    "def evolve_query(original_input: str, context, steps: int) -> str:\n",
    "    \"\"\"\n",
    "    Evolve a query through multiple transformation steps.\n",
    "    \n",
    "    Args:\n",
    "        original_input: The initial query to evolve\n",
    "        context: The context information\n",
    "        steps: Number of evolution steps to perform\n",
    "    \n",
    "    Returns:\n",
    "        The final evolved query\n",
    "    \"\"\"\n",
    "    current_input = original_input\n",
    "    \n",
    "    print(f\"\\nüìà Evolution Steps:\")\n",
    "    print(f\"Step 0 (Original): '{current_input}'\")\n",
    "    \n",
    "    for step in range(steps):\n",
    "        # Choose random template\n",
    "        template_idx = random.randint(0, len(evolution_templates) - 1)\n",
    "        chosen_template = evolution_templates[template_idx]\n",
    "        template_name = template_names[template_idx]\n",
    "        \n",
    "        # Prepare prompt\n",
    "        evolved_prompt = (\n",
    "            chosen_template\n",
    "            .replace(\"{context}\", str(context))\n",
    "            .replace(\"{original_input}\", current_input)\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Evolution step {step + 1}: Using {template_name} template\")\n",
    "        print(f\"\\nStep {step + 1}: Applying {template_name} template\")\n",
    "        \n",
    "        # Log the prompt being sent (truncated for readability)\n",
    "        logger.debug(f\"Prompt sent to LLM (step {step + 1}):\\n{evolved_prompt[:200]}...\")\n",
    "        \n",
    "        try:\n",
    "            response = llm.invoke(evolved_prompt)\n",
    "            current_input = response.content.strip()\n",
    "            \n",
    "            print(f\"Result: '{current_input}'\")\n",
    "            logger.info(f\"Evolution step {step + 1} completed successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Evolution step {step + 1} failed: {str(e)}\")\n",
    "            print(f\"‚ùå Evolution step {step + 1} failed, keeping previous version\")\n",
    "            break\n",
    "\n",
    "    return current_input\n",
    "\n",
    "# Perform query evolution\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"QUERY EVOLUTION PROCESS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    evolved_query = evolve_query(original_input, context, num_evolution_steps)\n",
    "    logger.info(\"Query evolution completed successfully\")\n",
    "    logger.info(f\"Final evolved query: '{evolved_query}'\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Query evolution failed: {str(e)}\")\n",
    "    evolved_query = original_input\n",
    "    print(f\"‚ùå Evolution failed, using original query: '{evolved_query}'\")\n"
   ],
   "id": "2a24b71d703809e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:14:02,301 - INFO - Starting query evolution process...\n",
      "2025-08-03 10:14:02,302 - INFO - Evolution configuration:\n",
      "2025-08-03 10:14:02,303 - INFO - - Original query: 'what is recipe of Apple Turnovers'\n",
      "2025-08-03 10:14:02,304 - INFO - - Evolution steps: 3\n",
      "2025-08-03 10:14:02,305 - INFO - - Context pieces: 1\n",
      "\n",
      "üîÑ Query Evolution Process\n",
      "- Original query: 'what is recipe of Apple Turnovers'\n",
      "- Evolution steps: 3\n",
      "- Available templates: Multi-context, Reasoning, Hypothetical scenario\n",
      "2025-08-03 10:14:02,307 - INFO - Loaded 3 evolution templates\n",
      "\n",
      "============================================================\n",
      "QUERY EVOLUTION PROCESS\n",
      "============================================================\n",
      "\n",
      "üìà Evolution Steps:\n",
      "Step 0 (Original): 'what is recipe of Apple Turnovers'\n",
      "2025-08-03 10:14:02,309 - INFO - Evolution step 1: Using Hypothetical scenario template\n",
      "\n",
      "Step 1: Applying Hypothetical scenario template\n",
      "2025-08-03 10:14:04,631 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Result: 'How do you make apple turnovers using two pie crusts and spiced apples?'\n",
      "2025-08-03 10:14:04,633 - INFO - Evolution step 1 completed successfully\n",
      "2025-08-03 10:14:04,633 - INFO - Evolution step 2: Using Hypothetical scenario template\n",
      "\n",
      "Step 2: Applying Hypothetical scenario template\n",
      "2025-08-03 10:14:04,934 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Result: 'How do you make Apple Turnovers using two pie crusts and spiced apples?'\n",
      "2025-08-03 10:14:04,936 - INFO - Evolution step 2 completed successfully\n",
      "2025-08-03 10:14:04,937 - INFO - Evolution step 3: Using Hypothetical scenario template\n",
      "\n",
      "Step 3: Applying Hypothetical scenario template\n",
      "2025-08-03 10:14:05,243 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Result: 'How do you make apple turnovers using two pie crusts and spiced apples?'\n",
      "2025-08-03 10:14:05,245 - INFO - Evolution step 3 completed successfully\n",
      "2025-08-03 10:14:05,246 - INFO - Query evolution completed successfully\n",
      "2025-08-03 10:14:05,246 - INFO - Final evolved query: 'How do you make apple turnovers using two pie crusts and spiced apples?'\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T06:44:24.329595Z",
     "start_time": "2025-08-03T06:44:24.323460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"\\nüéØ FINAL EVOLVED QUERY:\")\n",
    "print(f\"'{evolved_query}'\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "evolved_query\n"
   ],
   "id": "5e59a51f985a89f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ FINAL EVOLVED QUERY:\n",
      "'How do you make apple turnovers using two pie crusts and spiced apples?'\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'How do you make apple turnovers using two pie crusts and spiced apples?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Expected Output Generation\n",
    "\n",
    "Generate the expected answer for the evolved query based on the provided context.\n",
    "This creates the ground truth answer that can be used for evaluation.\n",
    "\n",
    "The prompt ensures the answer is:\n",
    "- Factually aligned with the provided context\n",
    "- Comprehensive and accurate\n",
    "- Suitable as a reference answer for evaluation\n",
    "\n"
   ],
   "id": "3649f33e6f503731"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T06:44:39.857255Z",
     "start_time": "2025-08-03T06:44:35.210044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logger.info(\"Starting expected output generation...\")\n",
    "\n",
    "print(\"\\nüîÑ Generating expected output (ground truth answer)...\")\n",
    "\n",
    "# Expected output template - DO NOT MODIFY\n",
    "expected_output_template = f\"\"\"\n",
    "I want you to generate an answer for the given `input`. This answer has to be factually aligned to the provided context.\n",
    "\n",
    "Context: {context}\n",
    "Input: {evolved_query}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Prepare the prompt\n",
    "prompt = expected_output_template.replace(\"{context}\", str(context)).replace(\"{evolved_query}\", evolved_query)\n",
    "\n",
    "logger.info(f\"Generating expected output for query: '{evolved_query}'\")\n",
    "\n",
    "try:\n",
    "    expected_output = llm.invoke(prompt)\n",
    "    logger.info(\"Expected output generated successfully\")\n",
    "    print(\"‚úÖ Expected output generated\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to generate expected output: {str(e)}\")\n",
    "    raise\n"
   ],
   "id": "b4f8bffd1bef3129",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:14:35,214 - INFO - Starting expected output generation...\n",
      "\n",
      "üîÑ Generating expected output (ground truth answer)...\n",
      "2025-08-03 10:14:35,215 - INFO - Generating expected output for query: 'How do you make apple turnovers using two pie crusts and spiced apples?'\n",
      "2025-08-03 10:14:39,853 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:14:39,855 - INFO - Expected output generated successfully\n",
      "‚úÖ Expected output generated\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T06:44:42.486054Z",
     "start_time": "2025-08-03T06:44:42.481813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EXPECTED OUTPUT (GROUND TRUTH)\")\n",
    "print(\"=\"*50)\n",
    "print(expected_output.content)\n",
    "print(\"=\"*50)\n"
   ],
   "id": "3520f9fe71726ac3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "EXPECTED OUTPUT (GROUND TRUTH)\n",
      "==================================================\n",
      "To make apple turnovers using two pie crusts and spiced apples, first let the pie crusts sit at room temperature. In a pan, combine 3 cups of thinly sliced apples (with peel), 1/2 cup brown sugar, 1 teaspoon cinnamon, and 2 teaspoons fresh lemon juice. Add 2 tablespoons of water to help with mixing, then cook over medium heat until the mixture bubbles. Reduce the heat to low, cover, and cook for 10 minutes, stirring occasionally. Gradually stir in 2 tablespoons flour, 2 tablespoons sugar, and 1/2 teaspoon salt until the filling thickens. Remove from heat and stir in 1 teaspoon vanilla and 2 tablespoons butter. On an ungreased cookie sheet, place the two 15 oz. prepared pie crusts. Spread the spiced apple mixture evenly over half of each crust. Fold the other half of the crust over the filling, pressing the edges together with a little warm water to seal. Cut small slits in the tops for ventilation. Bake at 375¬∞F for 30 minutes, or until the crusts are golden brown. Serve warm, optionally with ice cream or frozen yogurt. For individual turnovers, cut the pie crusts into smaller pieces before assembling.\n",
      "==================================================\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Synthetic Data Structure Creation\n",
    "Create a structured synthetic data object using Pydantic model.\n",
    "This ensures data consistency and provides a clean interface for the synthetic dataset.\n",
    "\n",
    "Structure includes:\n",
    "- query: The evolved query/question\n",
    "- expected_output: The ground truth answer\n",
    "- context: List of context strings used\n",
    "\n"
   ],
   "id": "effef0f23482959e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T06:44:57.024779Z",
     "start_time": "2025-08-03T06:44:57.015176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logger.info(\"Creating synthetic data structure...\")\n",
    "\n",
    "class SyntheticData(BaseModel):\n",
    "    \"\"\"\n",
    "    Pydantic model for synthetic data entries.\n",
    "    \n",
    "    Attributes:\n",
    "        query: The question or statement to be answered\n",
    "        expected_output: The ground truth answer\n",
    "        context: List of context strings that contain the information\n",
    "    \"\"\"\n",
    "    query: str\n",
    "    expected_output: Optional[str]\n",
    "    context: List[str]\n",
    "    \n",
    "    class Config:\n",
    "        \"\"\"Pydantic configuration\"\"\"\n",
    "        validate_assignment = True\n",
    "\n",
    "def as_str(x):\n",
    "    \"\"\"\n",
    "    Helper function to extract string content from various object types.\n",
    "    \n",
    "    Args:\n",
    "        x: Object that might have a 'content' attribute or is already a string\n",
    "        \n",
    "    Returns:\n",
    "        String representation of the object\n",
    "    \"\"\"\n",
    "    return x.content if hasattr(x, \"content\") else x\n",
    "\n",
    "# Create synthetic data entry\n",
    "try:\n",
    "    synthetic_data = SyntheticData(\n",
    "        query=evolved_query,\n",
    "        expected_output=as_str(expected_output),\n",
    "        context=context,\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Synthetic data structure created successfully\")\n",
    "    print(\"‚úÖ Synthetic data entry created\")\n",
    "    \n",
    "    # Initialize dataset list\n",
    "    synthetic_dataset = []\n",
    "    synthetic_dataset.append(synthetic_data)\n",
    "    \n",
    "    logger.info(f\"Synthetic dataset initialized with {len(synthetic_dataset)} entry\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to create synthetic data structure: {str(e)}\")\n",
    "    raise\n"
   ],
   "id": "a5bc6ac1cdbf54e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:14:57,018 - INFO - Creating synthetic data structure...\n",
      "2025-08-03 10:14:57,021 - INFO - Synthetic data structure created successfully\n",
      "‚úÖ Synthetic data entry created\n",
      "2025-08-03 10:14:57,022 - INFO - Synthetic dataset initialized with 1 entry\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T06:44:59.399818Z",
     "start_time": "2025-08-03T06:44:59.392591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SYNTHETIC DATA SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Query: {synthetic_data.query}\")\n",
    "print(f\"Context pieces: {len(synthetic_data.context)}\")\n",
    "print(f\"Expected output length: {len(synthetic_data.expected_output)} characters\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Display context for verification\n",
    "print(\"\\nContext used:\")\n",
    "for i, ctx in enumerate(synthetic_dataset[0].context):\n",
    "    print(f\"Context {i+1}: {ctx[:100]}...\")\n",
    "    if i >= 2:  # Limit display to first 3 contexts\n",
    "        print(f\"... and {len(synthetic_dataset[0].context) - 3} more context pieces\")\n",
    "        break\n",
    "\n",
    "synthetic_dataset[0].context\n"
   ],
   "id": "9f28cb827916465",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "SYNTHETIC DATA SUMMARY\n",
      "==================================================\n",
      "Query: How do you make apple turnovers using two pie crusts and spiced apples?\n",
      "Context pieces: 1\n",
      "Expected output length: 1119 characters\n",
      "==================================================\n",
      "\n",
      "Context used:\n",
      "Context 1: Apple Turnovers\n",
      "\n",
      "2 prepared 15 oz. pie crusts\n",
      "3 cups thinly sliced apples with peel\n",
      "1/2 cup brown su...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Apple Turnovers\\n\\n2 prepared 15 oz. pie crusts\\n3 cups thinly sliced apples with peel\\n1/2 cup brown sugar\\n1 tsp. cinnamon\\n2 tsp. fresh lemon juice\\n2 Tbsp. flour\\n2 Tbsp. sugar\\n1/2 tsp. salt\\n1 tsp. vanilla\\n2 Tbsp. Butter\\n\\nLet pie crust stand at room temperature while preparing the other\\ningredients. Combine apples, brown sugar, cinnamon and lemon \\njuice in pan. Add 2 Tbsp. water to allow easy mixing.  Cook\\nover medium heat until mixture bubbles.  Cover and continue cooking\\nover low heat for 10 minutes stirring occasionally.\\nGradually add flour, sugar and salt to mixture and cook until the \\nmixture begins to thicken.  Add in vanilla and butter and remove \\nmixture from heat.  Spread out pie crusts on ungreased cookie sheet.\\nSpread apple mixture evenly on half of each crust.  Fold over\\nother side of crust and press edges with a little warm water to\\nseal.  Cut small slits in top of crust and bake at 375 degrees\\nfor 30 minutes until crust is golden brown.  Serve warm.  These\\nturnovers will be a real hit.  If you would like, cut the pie crusts\\ninto smaller pieces and make individual turnovers.  You can serve\\nthese with ice cream or frozen yogurt.\\n\\nThe Skinny:  This recipe does have some sugar in it but it is not\\nreally that bad.  Leave off the ice cream and you will be doing\\nfine. ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8. Advanced Synthetic Dataset Generation with DeepEval\n",
    "Use DeepEval's advanced synthetic data generation capabilities to create\n",
    "additional high-quality synthetic datasets from documents.\n",
    "\n",
    "DeepEval provides:\n",
    "- Sophisticated query generation strategies\n",
    "- Multiple evolution techniques\n",
    "- Quality scoring and filtering\n",
    "- Batch processing capabilities\n",
    "\n",
    "This approach can generate larger volumes of synthetic data with consistent quality.\n",
    "\n"
   ],
   "id": "da8317962be3955"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T06:45:31.840454Z",
     "start_time": "2025-08-03T06:45:13.637838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logger.info(\"Starting advanced synthetic dataset generation with DeepEval...\")\n",
    "\n",
    "print(\"\\nüîÑ Generating synthetic datasets using DeepEval...\")\n",
    "print(\"This process may take several minutes depending on document size...\")\n",
    "\n",
    "# Document path for DeepEval processing\n",
    "deepeval_document_path = '../../Datasets/txt_example.txt'\n",
    "\n",
    "logger.info(f\"Processing document: {deepeval_document_path}\")\n",
    "\n",
    "try:\n",
    "    # Generate golden datasets using DeepEval\n",
    "    print(\"üîÑ DeepEval processing in progress...\")\n",
    "    result = deep_e.generate_goldens_from_documents(document_paths=deepeval_document_path)\n",
    "    \n",
    "    logger.info(\"DeepEval synthetic dataset generation completed\")\n",
    "    print(\"‚úÖ DeepEval dataset generation completed\")\n",
    "    \n",
    "    # Get results as DataFrame for analysis\n",
    "    df = deep_e.to_dataframe()\n",
    "    \n",
    "    logger.info(f\"Generated {len(df)} synthetic data entries using DeepEval\")\n",
    "    print(f\"üìä Generated {len(df)} entries in the DeepEval dataset\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"DeepEval dataset generation failed: {str(e)}\")\n",
    "    print(f\"‚ùå DeepEval generation failed: {str(e)}\")\n",
    "    df = None\n"
   ],
   "id": "a72d94e03b32105b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:15:13,641 - INFO - Starting advanced synthetic dataset generation with DeepEval...\n",
      "\n",
      "üîÑ Generating synthetic datasets using DeepEval...\n",
      "This process may take several minutes depending on document size...\n",
      "2025-08-03 10:15:13,642 - INFO - Processing document: ../../Datasets/txt_example.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c1dde4d36734a1f9418763c8a5ca701"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2m[Confident AI Synthesizer Log]\u001B[0m SUCCESS: \u001B[32mSuccessfully deleted\u001B[0m: .vector_db\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Confident AI Synthesizer Log]</span> SUCCESS: <span style=\"color: #008000; text-decoration-color: #008000\">Successfully deleted</span>: .vector_db\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:15:15,451 - INFO - Load pretrained SentenceTransformer: PartAI/Tooka-SBERT-V2-Large\n",
      "2025-08-03 10:15:22,021 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:22,031 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:22,033 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2m[Confident AI Synthesizer Log]\u001B[0m WARNING: \u001B[33mFiltering not applied\u001B[0m: Not enough chunks in smallest document\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Confident AI Synthesizer Log]</span> WARNING: <span style=\"color: #808000; text-decoration-color: #808000\">Filtering not applied</span>: Not enough chunks in smallest document\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2m[Confident AI Synthesizer Log]\u001B[0m SUCCESS: \u001B[32mSuccessfully deleted\u001B[0m: .vector_db\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Confident AI Synthesizer Log]</span> SUCCESS: <span style=\"color: #008000; text-decoration-color: #008000\">Successfully deleted</span>: .vector_db\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[2m[Confident AI Synthesizer Log]\u001B[0m SUCCESS: \u001B[32mContext Construction\u001B[0m: Utilizing 4 out of 4 chunks.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Confident AI Synthesizer Log]</span> SUCCESS: <span style=\"color: #008000; text-decoration-color: #008000\">Context Construction</span>: Utilizing 4 out of 4 chunks.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:15:24,614 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:24,634 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:24,708 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:25,433 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:25,435 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:25,453 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:26,356 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:26,357 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:27,175 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:27,176 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:27,177 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:27,677 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:27,679 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:28,065 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:28,351 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:28,599 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:28,701 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:28,728 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:28,956 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:29,043 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:29,447 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:29,448 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:29,449 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:30,213 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-03 10:15:31,027 - INFO - HTTP Request: POST http://localhost:11456/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:15:31,835 - INFO - DeepEval synthetic dataset generation completed\n",
      "‚úÖ DeepEval dataset generation completed\n",
      "2025-08-03 10:15:31,838 - INFO - Generated 24 synthetic data entries using DeepEval\n",
      "üìä Generated 24 entries in the DeepEval dataset\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T06:45:38.632256Z",
     "start_time": "2025-08-03T06:45:38.601410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display DeepEval results if successful\n",
    "if df is not None and not df.empty:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DEEPEVAL SYNTHETIC DATASET SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total entries: {len(df)}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    if len(df) > 0:\n",
    "        print(f\"\\nFirst entry preview:\")\n",
    "        for col in df.columns:\n",
    "            value = df.iloc[0][col]\n",
    "            if isinstance(value, str) and len(value) > 100:\n",
    "                print(f\"{col}: {value[:100]}...\")\n",
    "            else:\n",
    "                print(f\"{col}: {value}\")\n",
    "    \n",
    "    # Display DataFrame\n",
    "    display(df)\n",
    "else:\n",
    "    print(\"No DeepEval results to display\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PIPELINE COMPLETION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚úÖ Document processed: {len(raw_chunks)} chunks created\")\n",
    "print(f\"‚úÖ Embeddings generated: {len(embeddings_vectors)} vectors\")\n",
    "print(f\"‚úÖ Contexts selected: {len(contexts)} pieces\")\n",
    "print(f\"‚úÖ Query evolved: {num_evolution_steps} steps\")\n",
    "print(f\"‚úÖ Manual synthetic data: {len(synthetic_dataset)} entry\")\n",
    "if df is not None:\n",
    "    print(f\"‚úÖ DeepEval synthetic data: {len(df)} entries\")\n",
    "print(f\"Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "logger.info(\"Synthetic dataset generation pipeline completed successfully\")\n"
   ],
   "id": "f8c8a20a71dba838",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DEEPEVAL SYNTHETIC DATASET SUMMARY\n",
      "============================================================\n",
      "Total entries: 24\n",
      "Columns: ['input', 'actual_output', 'expected_output', 'context', 'retrieval_context', 'n_chunks_per_context', 'context_length', 'evolutions', 'context_quality', 'synthetic_input_quality', 'source_file']\n",
      "\n",
      "First entry preview:\n",
      "input: What ingredients and steps are required to prepare the thickened filling for apple turnovers using a...\n",
      "actual_output: None\n",
      "expected_output: To prepare the thickened filling for apple turnovers, combine 3 cups thinly sliced apples with peel,...\n",
      "context: ['Apple Turnovers\\n\\n2 prepared 15 oz. pie crusts\\n3 cups thinly sliced apples with peel\\n1/2 cup brown sugar\\n1 tsp. cinnamon\\n2 tsp. fresh lemon juice\\n2 Tbsp. flour\\n2 Tbsp. sugar\\n1/2 tsp. salt\\n1 tsp. vanilla\\n2 Tbsp. Butter\\n\\nLet pie crust stand at room temperature while preparing the other\\ningredients. Combine apples, brown sugar, cinnamon and lemon \\njuice', ' brown sugar, cinnamon and lemon \\njuice in pan. Add 2 Tbsp. water to allow easy mixing.  Cook\\nover medium heat until mixture bubbles.  Cover and continue cooking\\nover low heat for 10 minutes stirring occasionally.\\nGradually add flour, sugar and salt to mixture and cook until the \\nmixture begins to thicken.  Add in vanilla and butter and remove \\nmixture from heat.  Spread out pie crusts on ungreased cookie sheet']\n",
      "retrieval_context: None\n",
      "n_chunks_per_context: 2\n",
      "context_length: 765\n",
      "evolutions: ['Multi-context']\n",
      "context_quality: None\n",
      "synthetic_input_quality: 1.0\n",
      "source_file: ../../Datasets/txt_example.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                input actual_output  \\\n",
       "0   What ingredients and steps are required to pre...          None   \n",
       "1   How does cooking the apple filling before addi...          None   \n",
       "2   What ingredients and steps are required to pre...          None   \n",
       "3   How does cooking the apple filling before addi...          None   \n",
       "4   Bake individual apple turnovers in mini pie cr...          None   \n",
       "5   How should apple turnovers be baked, and what ...          None   \n",
       "6   What ingredients and steps are required to pre...          None   \n",
       "7   How does cooking the apple filling before addi...          None   \n",
       "8   Bake individual apple turnovers in mini pie cr...          None   \n",
       "9   How should apple turnovers be baked, and what ...          None   \n",
       "10  Cook apple, brown sugar, cinnamon, and lemon j...          None   \n",
       "11  How do you prepare individual apple turnovers ...          None   \n",
       "12  What ingredients and steps are required to pre...          None   \n",
       "13  How does cooking the apple filling before addi...          None   \n",
       "14  Bake individual apple turnovers in mini pie cr...          None   \n",
       "15  How should apple turnovers be baked, and what ...          None   \n",
       "16  Cook apple, brown sugar, cinnamon, and lemon j...          None   \n",
       "17  How do you prepare individual apple turnovers ...          None   \n",
       "18  What ingredients and steps are required to pre...          None   \n",
       "19  How does cooking the apple filling before addi...          None   \n",
       "20  Bake individual apple turnovers in mini pie cr...          None   \n",
       "21  How should apple turnovers be baked, and what ...          None   \n",
       "22  Cook apple, brown sugar, cinnamon, and lemon j...          None   \n",
       "23  How do you prepare individual apple turnovers ...          None   \n",
       "\n",
       "                                      expected_output  \\\n",
       "0   To prepare the thickened filling for apple tur...   \n",
       "1   Cooking the apple filling before adding it to ...   \n",
       "2   To prepare the thickened filling for apple tur...   \n",
       "3   Cooking the apple filling before adding it to ...   \n",
       "4   Bake individual apple turnovers in mini pie cr...   \n",
       "5   Bake apple turnovers at 375 degrees for 30 min...   \n",
       "6   To prepare the thickened filling for apple tur...   \n",
       "7   Cooking the apple filling before adding it to ...   \n",
       "8   Bake individual apple turnovers in mini pie cr...   \n",
       "9   Bake apple turnovers at 375 degrees for 30 min...   \n",
       "10  Cook apple, brown sugar, cinnamon, and lemon j...   \n",
       "11  Preheat oven to 375¬∞F. Roll out pre-made pie c...   \n",
       "12  To prepare the thickened filling for apple tur...   \n",
       "13  Cooking the apple filling before adding it to ...   \n",
       "14  Bake individual apple turnovers in mini pie cr...   \n",
       "15  Bake apple turnovers at 375 degrees for 30 min...   \n",
       "16  Cook apple, brown sugar, cinnamon, and lemon j...   \n",
       "17  Preheat oven to 375¬∞F. Roll out pre-made pie c...   \n",
       "18  To prepare the thickened filling for apple tur...   \n",
       "19  Cooking the apple filling before adding it to ...   \n",
       "20  Bake individual apple turnovers in mini pie cr...   \n",
       "21  Bake apple turnovers at 375 degrees for 30 min...   \n",
       "22  Cook apple, brown sugar, cinnamon, and lemon j...   \n",
       "23  Preheat oven to 375¬∞F. Roll out pre-made pie c...   \n",
       "\n",
       "                                              context retrieval_context  \\\n",
       "0   [Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...              None   \n",
       "1   [Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...              None   \n",
       "2   [Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...              None   \n",
       "3   [Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...              None   \n",
       "4   [ pie crusts\\ninto smaller pieces and make ind...              None   \n",
       "5   [ pie crusts\\ninto smaller pieces and make ind...              None   \n",
       "6   [Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...              None   \n",
       "7   [Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...              None   \n",
       "8   [ pie crusts\\ninto smaller pieces and make ind...              None   \n",
       "9   [ pie crusts\\ninto smaller pieces and make ind...              None   \n",
       "10  [ brown sugar, cinnamon and lemon \\njuice in p...              None   \n",
       "11  [ brown sugar, cinnamon and lemon \\njuice in p...              None   \n",
       "12  [Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...              None   \n",
       "13  [Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...              None   \n",
       "14  [ pie crusts\\ninto smaller pieces and make ind...              None   \n",
       "15  [ pie crusts\\ninto smaller pieces and make ind...              None   \n",
       "16  [ brown sugar, cinnamon and lemon \\njuice in p...              None   \n",
       "17  [ brown sugar, cinnamon and lemon \\njuice in p...              None   \n",
       "18  [Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...              None   \n",
       "19  [Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...              None   \n",
       "20  [ pie crusts\\ninto smaller pieces and make ind...              None   \n",
       "21  [ pie crusts\\ninto smaller pieces and make ind...              None   \n",
       "22  [ brown sugar, cinnamon and lemon \\njuice in p...              None   \n",
       "23  [ brown sugar, cinnamon and lemon \\njuice in p...              None   \n",
       "\n",
       "    n_chunks_per_context  context_length       evolutions context_quality  \\\n",
       "0                      2             765  [Multi-context]            None   \n",
       "1                      2             765    [Comparative]            None   \n",
       "2                      2             765  [Multi-context]            None   \n",
       "3                      2             765    [Comparative]            None   \n",
       "4                      2             658     [In-Breadth]            None   \n",
       "5                      2             658    [Constrained]            None   \n",
       "6                      2             765  [Multi-context]            None   \n",
       "7                      2             765    [Comparative]            None   \n",
       "8                      2             658     [In-Breadth]            None   \n",
       "9                      2             658    [Constrained]            None   \n",
       "10                     2             818     [In-Breadth]            None   \n",
       "11                     2             818    [Constrained]            None   \n",
       "12                     2             765  [Multi-context]            None   \n",
       "13                     2             765    [Comparative]            None   \n",
       "14                     2             658     [In-Breadth]            None   \n",
       "15                     2             658    [Constrained]            None   \n",
       "16                     2             818     [In-Breadth]            None   \n",
       "17                     2             818    [Constrained]            None   \n",
       "18                     2             765  [Multi-context]            None   \n",
       "19                     2             765    [Comparative]            None   \n",
       "20                     2             658     [In-Breadth]            None   \n",
       "21                     2             658    [Constrained]            None   \n",
       "22                     2             818     [In-Breadth]            None   \n",
       "23                     2             818    [Constrained]            None   \n",
       "\n",
       "    synthetic_input_quality                     source_file  \n",
       "0                       1.0  ../../Datasets/txt_example.txt  \n",
       "1                       1.0  ../../Datasets/txt_example.txt  \n",
       "2                       1.0  ../../Datasets/txt_example.txt  \n",
       "3                       1.0  ../../Datasets/txt_example.txt  \n",
       "4                       1.0  ../../Datasets/txt_example.txt  \n",
       "5                       1.0  ../../Datasets/txt_example.txt  \n",
       "6                       1.0  ../../Datasets/txt_example.txt  \n",
       "7                       1.0  ../../Datasets/txt_example.txt  \n",
       "8                       1.0  ../../Datasets/txt_example.txt  \n",
       "9                       1.0  ../../Datasets/txt_example.txt  \n",
       "10                      1.0  ../../Datasets/txt_example.txt  \n",
       "11                      1.0  ../../Datasets/txt_example.txt  \n",
       "12                      1.0  ../../Datasets/txt_example.txt  \n",
       "13                      1.0  ../../Datasets/txt_example.txt  \n",
       "14                      1.0  ../../Datasets/txt_example.txt  \n",
       "15                      1.0  ../../Datasets/txt_example.txt  \n",
       "16                      1.0  ../../Datasets/txt_example.txt  \n",
       "17                      1.0  ../../Datasets/txt_example.txt  \n",
       "18                      1.0  ../../Datasets/txt_example.txt  \n",
       "19                      1.0  ../../Datasets/txt_example.txt  \n",
       "20                      1.0  ../../Datasets/txt_example.txt  \n",
       "21                      1.0  ../../Datasets/txt_example.txt  \n",
       "22                      1.0  ../../Datasets/txt_example.txt  \n",
       "23                      1.0  ../../Datasets/txt_example.txt  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>actual_output</th>\n",
       "      <th>expected_output</th>\n",
       "      <th>context</th>\n",
       "      <th>retrieval_context</th>\n",
       "      <th>n_chunks_per_context</th>\n",
       "      <th>context_length</th>\n",
       "      <th>evolutions</th>\n",
       "      <th>context_quality</th>\n",
       "      <th>synthetic_input_quality</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What ingredients and steps are required to pre...</td>\n",
       "      <td>None</td>\n",
       "      <td>To prepare the thickened filling for apple tur...</td>\n",
       "      <td>[Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>765</td>\n",
       "      <td>[Multi-context]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does cooking the apple filling before addi...</td>\n",
       "      <td>None</td>\n",
       "      <td>Cooking the apple filling before adding it to ...</td>\n",
       "      <td>[Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>765</td>\n",
       "      <td>[Comparative]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What ingredients and steps are required to pre...</td>\n",
       "      <td>None</td>\n",
       "      <td>To prepare the thickened filling for apple tur...</td>\n",
       "      <td>[Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>765</td>\n",
       "      <td>[Multi-context]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does cooking the apple filling before addi...</td>\n",
       "      <td>None</td>\n",
       "      <td>Cooking the apple filling before adding it to ...</td>\n",
       "      <td>[Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>765</td>\n",
       "      <td>[Comparative]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bake individual apple turnovers in mini pie cr...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bake individual apple turnovers in mini pie cr...</td>\n",
       "      <td>[ pie crusts\\ninto smaller pieces and make ind...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>658</td>\n",
       "      <td>[In-Breadth]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How should apple turnovers be baked, and what ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bake apple turnovers at 375 degrees for 30 min...</td>\n",
       "      <td>[ pie crusts\\ninto smaller pieces and make ind...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>658</td>\n",
       "      <td>[Constrained]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What ingredients and steps are required to pre...</td>\n",
       "      <td>None</td>\n",
       "      <td>To prepare the thickened filling for apple tur...</td>\n",
       "      <td>[Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>765</td>\n",
       "      <td>[Multi-context]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How does cooking the apple filling before addi...</td>\n",
       "      <td>None</td>\n",
       "      <td>Cooking the apple filling before adding it to ...</td>\n",
       "      <td>[Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>765</td>\n",
       "      <td>[Comparative]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bake individual apple turnovers in mini pie cr...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bake individual apple turnovers in mini pie cr...</td>\n",
       "      <td>[ pie crusts\\ninto smaller pieces and make ind...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>658</td>\n",
       "      <td>[In-Breadth]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How should apple turnovers be baked, and what ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bake apple turnovers at 375 degrees for 30 min...</td>\n",
       "      <td>[ pie crusts\\ninto smaller pieces and make ind...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>658</td>\n",
       "      <td>[Constrained]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cook apple, brown sugar, cinnamon, and lemon j...</td>\n",
       "      <td>None</td>\n",
       "      <td>Cook apple, brown sugar, cinnamon, and lemon j...</td>\n",
       "      <td>[ brown sugar, cinnamon and lemon \\njuice in p...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>818</td>\n",
       "      <td>[In-Breadth]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How do you prepare individual apple turnovers ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Preheat oven to 375¬∞F. Roll out pre-made pie c...</td>\n",
       "      <td>[ brown sugar, cinnamon and lemon \\njuice in p...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>818</td>\n",
       "      <td>[Constrained]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What ingredients and steps are required to pre...</td>\n",
       "      <td>None</td>\n",
       "      <td>To prepare the thickened filling for apple tur...</td>\n",
       "      <td>[Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>765</td>\n",
       "      <td>[Multi-context]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>How does cooking the apple filling before addi...</td>\n",
       "      <td>None</td>\n",
       "      <td>Cooking the apple filling before adding it to ...</td>\n",
       "      <td>[Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>765</td>\n",
       "      <td>[Comparative]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bake individual apple turnovers in mini pie cr...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bake individual apple turnovers in mini pie cr...</td>\n",
       "      <td>[ pie crusts\\ninto smaller pieces and make ind...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>658</td>\n",
       "      <td>[In-Breadth]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How should apple turnovers be baked, and what ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bake apple turnovers at 375 degrees for 30 min...</td>\n",
       "      <td>[ pie crusts\\ninto smaller pieces and make ind...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>658</td>\n",
       "      <td>[Constrained]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cook apple, brown sugar, cinnamon, and lemon j...</td>\n",
       "      <td>None</td>\n",
       "      <td>Cook apple, brown sugar, cinnamon, and lemon j...</td>\n",
       "      <td>[ brown sugar, cinnamon and lemon \\njuice in p...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>818</td>\n",
       "      <td>[In-Breadth]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How do you prepare individual apple turnovers ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Preheat oven to 375¬∞F. Roll out pre-made pie c...</td>\n",
       "      <td>[ brown sugar, cinnamon and lemon \\njuice in p...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>818</td>\n",
       "      <td>[Constrained]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What ingredients and steps are required to pre...</td>\n",
       "      <td>None</td>\n",
       "      <td>To prepare the thickened filling for apple tur...</td>\n",
       "      <td>[Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>765</td>\n",
       "      <td>[Multi-context]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How does cooking the apple filling before addi...</td>\n",
       "      <td>None</td>\n",
       "      <td>Cooking the apple filling before adding it to ...</td>\n",
       "      <td>[Apple Turnovers\\n\\n2 prepared 15 oz. pie crus...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>765</td>\n",
       "      <td>[Comparative]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Bake individual apple turnovers in mini pie cr...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bake individual apple turnovers in mini pie cr...</td>\n",
       "      <td>[ pie crusts\\ninto smaller pieces and make ind...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>658</td>\n",
       "      <td>[In-Breadth]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>How should apple turnovers be baked, and what ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bake apple turnovers at 375 degrees for 30 min...</td>\n",
       "      <td>[ pie crusts\\ninto smaller pieces and make ind...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>658</td>\n",
       "      <td>[Constrained]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Cook apple, brown sugar, cinnamon, and lemon j...</td>\n",
       "      <td>None</td>\n",
       "      <td>Cook apple, brown sugar, cinnamon, and lemon j...</td>\n",
       "      <td>[ brown sugar, cinnamon and lemon \\njuice in p...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>818</td>\n",
       "      <td>[In-Breadth]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>How do you prepare individual apple turnovers ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Preheat oven to 375¬∞F. Roll out pre-made pie c...</td>\n",
       "      <td>[ brown sugar, cinnamon and lemon \\njuice in p...</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>818</td>\n",
       "      <td>[Constrained]</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>../../Datasets/txt_example.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PIPELINE COMPLETION SUMMARY\n",
      "============================================================\n",
      "‚úÖ Document processed: 1 chunks created\n",
      "‚úÖ Embeddings generated: 1 vectors\n",
      "‚úÖ Contexts selected: 1 pieces\n",
      "‚úÖ Query evolved: 3 steps\n",
      "‚úÖ Manual synthetic data: 1 entry\n",
      "‚úÖ DeepEval synthetic data: 24 entries\n",
      "Completed at: 2025-08-03 10:15:38\n",
      "============================================================\n",
      "2025-08-03 10:15:38,630 - INFO - Synthetic dataset generation pipeline completed successfully\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7d7395a913241a2e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
